# -*- coding: utf-8 -*-
"""Prediksi harga mobil bekas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12e3FwJ0aEJVdbh8pnwWXDgn-LfH9s2bm

# Data Loading

Pada tahap ini, kita akan import library yang diperlukan untuk persiapan data terlebih dahulu.
"""

# import library untuk persiapan data
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

"""Setelah itu, kita akan menampilkan dataframe yang kita miliki."""

# menampilkan dataframe
car_df = pd.read_csv('cardekho.csv')
car_df

"""Terlihat bahwa kita memiliki 8128 data dengan 12 kolom, yaitu name, year,selling_price, km_driven, fuel, seller_type, transmission, owner, mileage(km/ltr/kg), engine, max_power, dan seats

# Data Understanding
"""

# melihat info variabel data
car_df.info()

"""Terlihat bahwa:
- Terdapat 1 kolom target fitur, yaitu kolom 'selling_price'
- Ada 4 kolom fitur numerik yang kita pakai, yaitu km_driven, mileage(km/ltr/kg), engine, dan max_power
- Ada 7 kolom kategorikal yang kita pakai, yaitu name, year, fuel, seller_type, transmission, owner, dan seats
- Pada kolom 'max_power', perlu ada nya penyesuaian tipe data menjadi float
- Pada kolom 'seats', perlu ada nya penyesuaian tipe data menjadi integer
- Pada kolom mileage(km/ltr/kg), nama kolom bisa kita singkat sehingga memudahkan pada proses EDA.

Terlihat ada beberapa kolom mempunyai nilai null. Selanjutnya kita akan mengecek berapa nilai null tiap kolom.
"""

# mengecek nilai null
car_df.isnull().sum()

"""Selanjutnya, kita akan mengecek nilai duplikat."""

#mengecek nilai duplikat
duplicate_rows = car_df.duplicated()

print(duplicate_rows.sum())

"""Pada langkah selanjutnya, kita akan mengecek *outlier* dari data numerik di dataframe kita."""

#mengecek outlier selling price
sns.boxplot(x=car_df['selling_price'])

#mengecek outlier km driven
sns.boxplot(x=car_df['km_driven'])

#mengecek outlier mileage
sns.boxplot(x=car_df['mileage(km/ltr/kg)'])

#mengecek outlier engine
sns.boxplot(x=car_df['engine'])

# mengecek outlier max power
sns.boxplot(x=car_df['max_power'])

"""Berdasarkan yang kita dapat, dapat disimpulkan bahwa:
- Terdapat nilai null pada kolom mileage(km/ltr/kg), engine, max_power, dan seats
- Terdapat data duplikat sebanyak 1202 data
- Setiap data numerik memiliki nilai *Outlier*

# Data Preparation

Data preparation penting antara lain untuk meningkatkan kualitas data, mempermudah analisis dan insight yang didapat, dan meningkatkan performa model machine learning. Tahap-tahap Data Preparation antara lain:
- Data Cleaning
- EDA
- Data Transformation

## Data Cleaning

Pada langkah data cleaning ini, kita akan melakukan langkah-langkah sebagai berikut:
- Menghapus data yang memiliki nilai null
- Menghapus data duplikat
- Mengganti tipe data pada kolom 'max power'
- Mengganti tipe data pada kolom 'seats'
- Mengganti nama kolom mileage(km/ltr/kg) menjadi mileage
- Menghapus *outlier* pada data

### Remove null value

Pada tahap ini, kita akan menghapus data yang memiliki nilai Null
"""

# menghapus nilai null
car_df = car_df.dropna()

"""### Remove Duplicate Data

Pada tahap ini, kita akan menghapus data duplikat untuk menghindari terjadi nya overfitting
"""

#mengecek nilai duplikat
duplicate_rows = car_df.duplicated()

print(duplicate_rows.sum())

#menghapus nilai duplikat
car_df = car_df.drop_duplicates()

#mengecek info variabel
car_df.info()

"""Untuk saat ini, kita mempunyai 6718 data setelah proses penghapusan data yang memiliki nilai null dan data duplikat

### Change data type and column name

#### Max Power

Pada kolom ini, ada data yang mempunyai nilai ' ' sehungga kolom tidak bisa langsung diubah ke tipe data float. Oleh karena itu, kita perlu menghapus data yang memiliki nilai ' ' kemudian baru kita mengubah tipe data pada kolom max power menjadi float
"""

#mengecek nilai pada max power yang memiliki nilai ' '
car_df[car_df['max_power'] == ' ']

#menghapus data yang memiliki nilai ' '
car_df['max_power'] = car_df['max_power'].replace(' ', np.nan)

car_df = car_df.dropna(subset=['max_power'])

#mengecek kembali nilai pada max power yang memiliki nilai ' '
car_df[car_df['max_power'] == ' ']

#mengganti tipe data max power
car_df['max_power'] = car_df['max_power'].astype('float')

"""#### Seats

Pada kolom ini, kita akan mengganti tipe data seats dari sebelumnya float menjadi integer karena seats tidak mungkin bilangan pecahan.
"""

#mengganti tipe data seats
car_df['seats'] = car_df['seats'].astype(int)

"""#### Mileage(km/ltr/kg)

Pada kolom ini, kita akan mengganti nama kolom menjadi mileage supaya mempermudah dalam penulisan nanti.
"""

#mengganti nama kolom mileage(km/ltr/kg) menjadi mileage
car_df.rename(columns={'mileage(km/ltr/kg)':'mileage'}, inplace = True)

"""### Remove Outlier

Pada tahap ini, kita akan mendeklarasikan 'num_features' terlebih dahulu sebagai kolom yang mempunyai fitur numerik. Setelah itu, kita akan menghapus nilai *outlier* pada data menggunakan metode IQR.
"""

#mendeklarasikan num_features sebagai fitur numerik
num_features = ['selling_price',	'km_driven',	'mileage',	'engine',	'max_power']
car_df[num_features]

#menghapus outlier menggunakan IQR
Q1 = car_df[num_features].quantile(0.25)
Q3 = car_df[num_features].quantile(0.75)
IQR=Q3-Q1
car_df=car_df[~((car_df[num_features]<(Q1-1.5*IQR))|(car_df[num_features]>(Q3+1.5*IQR))).any(axis=1)]

#mengecek info variabel
car_df.info()

"""Sehingga kita memiliki data bersih sebanyak 5385 data.

Berikut merupaka deskripsi stastistik data dengan fitur numerik yang telah bersih
"""

#mengecek deskripsi stastistik
car_df.describe()

"""## EDA

Dengan melakukan EDA, pengguna akan sangat terbantu dalam mendeteksi kesalahan dari awal, mengetahui hubungan antar data serta dapat menggali faktor-faktor penting dari data.

Pada tahap ini, kita akan mendefinisikan kolom 'cat_features' terlebih dahulu. Setelah itu, kita akan mendapatkan *insight* dari EDA yang kita lakukan.
"""

#mendeklarasikan cat_features sebagai fitur kategori
cat_features = ['year', 'name',	'fuel',	'seller_type', 'transmission', 'owner', 'seats']

"""### Univariate Analysis

#### Categorical Features
"""

#visualisasi 5 besar dari kolom year
feature = cat_features[0]
count = car_df[feature].value_counts()
percent = 100*car_df[feature].value_counts(normalize=True)

top_5_count = count.head(5)
top_5_percent = percent.head(5)

df = pd.DataFrame({'jumlah sampel':top_5_count, 'persentase':top_5_percent.round(1)})
print(df)
top_5_count.plot(kind='bar', title=feature);

"""Terlihat bahwa
- Top 5 mobil bekas yang paling banyak merupakan mobil keluaran tahun 2017, 2016, 2015, 2018, dan 2012
- Mobil keluaran 2017 merupakan mobil bekas terbanyak dengan 697 data dengan persentase sebesar 12,9%
"""

#visualisasi 5 besar dari kolom name
feature = cat_features[1]
count = car_df[feature].value_counts()
percent = 100*car_df[feature].value_counts(normalize=True)

top_5_count = count.head(5)
top_5_percent = percent.head(5)

df = pd.DataFrame({'jumlah sampel':top_5_count, 'persentase':top_5_percent.round(1)})
print(df)
top_5_count.plot(kind='bar', title=feature);

"""Terlihat bahwa
- Top 5 mobil bekas yang paling banyak adalah Maruti Swift Dzire VDI, Maruti Alto 800 LXI, Maruti Alto LXi, Maruti Swift VDI, dan Maruti Alto K10 VXI
- Mobil Maruti Swift Dzire VDI merupakan mobil terbanyak dengan 118 data dengan persentase sebesar 2,12%
"""

#visualisasi dari kolom fuel
feature = cat_features[2]
count = car_df[feature].value_counts()
percent = 100*car_df[feature].value_counts(normalize=True)

df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Terlihat bahwa
- Mobil bekas paling banyak menggunakan tipe bahan bakar Petrol/Bensin dengan 2848 data dengan persentase 52,9%
- Mobil bekas paling sedikit menggunakan tipe bahan bakar LPG dengan 34 data dengan persentase 0,6%
"""

#visualisasi  dari kolom seller type
feature = cat_features[3]
count = car_df[feature].value_counts()
percent = 100*car_df[feature].value_counts(normalize=True)

df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Terlihat bahwa
- Mobil bekas paling banyak menggunakan tipe seller individual dengan 4877 data dengan persentase 90,6%
- Mobil bekas paling sedikit menggunakan tipe seller dealer terpercaya dengan 25 data dengan persentase 0,5%
"""

#visualisasi dari kolom transmission
feature = cat_features[4]
count = car_df[feature].value_counts()
percent = 100*car_df[feature].value_counts(normalize=True)

df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Terlihat bahwa
- Mobil bekas paling banyak menggunakan transmisi manual dengan 5099 data dengan persentase 94,7%
- Mobil bekas paling sedikit menggunakan transmisi otomatis dengan 286 data dengan persentase 5,3%
"""

#visualisasi dari kolom owner
feature = cat_features[5]
count = car_df[feature].value_counts()
percent = 100*car_df[feature].value_counts(normalize=True)

top_5_count = count.head(5)
top_5_percent = percent.head(5)

df = pd.DataFrame({'jumlah sampel':top_5_count, 'persentase':top_5_percent.round(1)})
print(df)
top_5_count.plot(kind='bar', title=feature);

"""Terlihat bahwa
- Mobil bekas paling banyak merupakan pemilik pertama dengan 3404 data dengan persentase 63,2%
- Mobil bekas paling sedikit merupakan pemilik keempat atau lebih dengan 116 data dengan persentase 2,2%
"""

#visualisasi 5 besar dali kolom seats
feature = cat_features[6]
count = car_df[feature].value_counts()
percent = 100*car_df[feature].value_counts(normalize=True)

top_5_count = count.head(5)
top_5_percent = percent.head(5)

df = pd.DataFrame({'jumlah sampel':top_5_count, 'persentase':top_5_percent.round(1)})
print(df)
top_5_count.plot(kind='bar', title=feature);

"""Terlihat bahwa
- Top 5 mobil bekas yang paling banyak mempunyai kursi sebanyak 5, 7, 4, 8, dan 6 kursi
- Mobil yang memiliki 5 kursi merupakan mobil bekas terbanyak dengan 4906 data dengan persentase sebesar 91,1%

#### Numerical Features
"""

#Visualisasi univariate analysis untuk fitur numerik
car_df.hist(bins=50, figsize=(20,15))
plt.show()

"""Terlihat bahwa
- Banyak harga jual mobil yang termasuk murah di sekitar 200000 sd 400000.
- Banyak mobil bekas yang dijual telah digunakan sepanjang 2500 sampai 12500 km.
- Banyak mobil bekas yang dijual menempuh jarah 15 sd 25 km per liter bahan bakarnya.
- Kebanyakan mobil bekas yang dijual memiliki mesin sebesar 1200 cc.

### Multivariate Analysis
"""

#Visualisasi multivariate analysis untuk fitur kategori
for col in cat_features:
  sns.catplot(x=col, y="selling_price", kind="bar", dodge=False, height = 4, aspect = 3,  data=car_df, palette="Set3")
  plt.title("Rata-rata 'selling_price' Relatif terhadap - {}".format(col))

"""Terlihat bahwa
- Pada fitur 'year', rata-rata harga semakin naik. Mobil keluaran tahun 2019 mempunyai rata-rata harga tertinggi diantara tahun lainnya.
- Pada fitur 'fuel', Mobil bertipe bahan bakar diesel/solar mempunyai rata-rata harga tertinggi dibandingkan tipe bahan bakar lainnya.
- Pada fitur 'seller', Mobil bertipe seller dealer terpercaya mempunyai rata-rata harga tertinggi dibandingkan tipe bahan bakar lainnya.
- Pada fitur 'transmission', Mobil bertipe transmisi otomatis mempunyai rata-rata harga lebih tinggi dibandingkan tipe transmisi manual.
- Pada fitur 'owner', Mobil bertipe kepemilikan orang pertama mempunyai rata-rata harga tertinggi dibandingkan tipe bahan bakar lainnya.
- Pada fitur 'seats', Mobil yang mempunyai 7 kursi mempunyai rata-rata harga tertinggi dibandingkan tipe bahan bakar lainnya.

"""

#Visualisasi multivariate analysis untuk fitur numerik
sns.pairplot(car_df, diag_kind = 'kde')

"""Terlihat bahwa
- Pada fitur 'year', 'mileage', 'engine', dan 'max_power' memiliki korelasi positif dengan 'selling_price'
- Pada fitur 'km_driven' memiliki korelasi negatif dengan 'selling_price
- Pada fitur 'seats' memiliki korelasi yang acak dengan 'selling_price'

### Correlasion Matrix
"""

#Membuat confussion matrix
plt.figure(figsize=(10, 8))
correlation_matrix = car_df[num_features].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Terlihat bahwa masing-masing fitur memiliki relasi yang cukup kuat dengan 'selling_price', sehingga tidak ada penghapusan fitur yang tidak memiliki korelasi.

## Data Transformation

Data Transformation merupakan tahap transformasi data kita. Data Transformation penting dilakukan supaya data kita bisa melakukan modeling data dengan baik.
"""

car_df['name'].nunique()

"""Pada tahap ini, kita akan melakukan 2 kali encoding pada data, yaitu target encoding pada fitur 'name' karena fitur tersebut memiliki banyak nilai unik, yaitu 1456 nilai unik. Serta melakukan label encoding pada kolom kategorikal selain name.  Kita akan melakukan import library untuk target encoding dan label encoding terlebih dahulu."""

#import library untuk target encoding dan label encoder
from sklearn.preprocessing import TargetEncoder, LabelEncoder

target_encoder = TargetEncoder()
label_encoder = LabelEncoder()

"""### Target Encoding

Target encoder dipilih pada kolom 'name' karena Encoder ini mengurangi dimensionalitas dan mempertahankan hubungan antara fitur kategoris dan variabel target. Terget Encoder membutuhkan kolom y('selling_price') untuk menghitung rata-rata target per kategori. Proses yang dilakukan yaitu mengubah isi kolom 'selling_price' terlebih dahulu ke bentuk logaritma nya karena  target dari kolom y memiliki nilai yang cukup besar, sehingga berimbas ke Target Encoding yang tidak efektif. Setelah itu dilakukan proses Target Encoding. Setelah itu, kolom 'selling_price_log' akan dihapus.
"""

#membuat kolom selling_price_log dan proses target encoding
car_df['selling_price_log'] = np.log1p(car_df['selling_price'])
car_df['name']= target_encoder.fit_transform(car_df[['name']], car_df['selling_price_log'])

#mengecek kembali dataframe
car_df.head()

#menghapus kolom selling_price_log
car_df.drop(['selling_price_log'], axis = 1, inplace = True)

"""### Label Encoding

Setelah itu dilakukan proses Label Encoding. Label Encoding dipilih karena lebih efisien dalam memori dan komputasi. Label Encoding dilakukan di kolom kategori selain 'name'.
"""

#label encoding untuk kolom fuel
car_df['fuel']= label_encoder.fit_transform(car_df['fuel'])

car_df['fuel'].unique()

#label encoding untuk kolom seller type
car_df['seller_type']= label_encoder.fit_transform(car_df['seller_type'])

car_df['seller_type'].unique()

#label encoding untuk kolom transmission
car_df['transmission']= label_encoder.fit_transform(car_df['transmission'])

car_df['transmission'].unique()

#label encoding untuk kolom owner
car_df['owner']= label_encoder.fit_transform(car_df['owner'])

car_df['owner'].unique()

#mengecek kembali dataframe
car_df.head()

car_df.info()

"""Terlihat bahwa data kita sudah menjadi tipe data numerik semua sehingga kita bisa lanjut ke tahap berikutnya.

### Train_Test_Split

Train test split adalah proses membagi data menjadi data latih dan data uji. Pada proses ini, kita membagi data dengan rasio 80:20. Kemudian didapat hasil pembagian data latih dan data uji.
"""

#mendefinisikan variabel x dan y
x = car_df.drop(['selling_price'], axis = 1)
y = car_df['selling_price']

#proses train test split
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 123)

#Melihat banyaknya data train dan data test setelah train test split
print(f'Total # of sample in whole dataset: {len(x)}')
print(f'Total # of sample in train dataset: {len(x_train)}')
print(f'Total # of sample in test dataset: {len(x_test)}')

"""Terlihat bahwa kita mempunyai 4308 data latih dan 1077 data uji.

### Standarization

Standarisasi fitur numerik memiliki tujuan untuk memastikan bahwa semua fitur berkontribusi secara proporsional terhadap model. StandardScaler akan menghasilkan distribusi dengan standar deviasi sama dengan 1 dan mean sama dengan 0.
"""

#proses standarisasi pada data latih
from sklearn.preprocessing import StandardScaler

numerical_features = ['km_driven',	'mileage',	'engine',	'max_power']
scaler = StandardScaler()
scaler.fit(x_train[numerical_features])
x_train[numerical_features] = scaler.transform(x_train.loc[:, numerical_features])
x_train[numerical_features].head()

"""# Modeling

Modeling adalah tahapan di mana kita menggunakan algoritma machine learning untuk menjawab problem statement dari tahap business understanding. Kita akan memakai 3 algoritma, yaitu Random Forest Regressor, XGBoost, Dan Gradient Boosting. Kita akan memuat hasil MSE dari 3 algoritma tersebut dan membandingkan algoritma mana yang memiliki kinerja yang lebih baik.
"""

#membuat datafram yang memuat hasil MSE 3 model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=[ 'RandomForest', 'XGBoost', 'GradientBoosting'])

#import MSE
from sklearn.metrics import mean_squared_error

"""## Random Forest Regressor"""

#import, proses Random Forest Regressor, dan menyimpan masih MSE
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=100, random_state=123)
rf.fit(x_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred = rf.predict(x_train), y_true=y_train)

"""## XGBoost"""

#install xgboost
!pip install xgboost

#import, proses XGBoost, dan menyimpan masih MSE
import xgboost as xgb

xgb_r = xgb.XGBRegressor(objective ='reg:squarederror', random_state=123)
xgb_r.fit(x_train, y_train)

models.loc['train_mse','XGBoost'] = mean_squared_error(y_pred=xgb_r.predict(x_train), y_true=y_train)

"""## Gradient Boosting"""

#import, proses Gradient Boosting, dan menyimpan masih MSE
from sklearn.ensemble import GradientBoostingRegressor

gbr = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, random_state=123)
gbr.fit(x_train, y_train)

models.loc['train_mse','GradientBoosting'] = mean_squared_error(y_pred=gbr.predict(x_train), y_true=y_train)

"""# Evaluation"""

#standarisasi pada data uji
x_test.loc[:, numerical_features] = scaler.transform(x_test[numerical_features])

#Menampilkan hasil MSE 3 model untuk data latih dan data uji

mse = pd.DataFrame(columns=['train', 'test'], index=['RF','XGBoost','GradientBoosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = { 'RF': rf, 'XGBoost':xgb_r, 'GradientBoosting':gbr}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(x_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(x_test))/1e3

# Panggil mse
mse

#visualisasi MSE 3 model
fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Bisa kita lihat bahwa
- Random Forest Regressor memiliki error di data latih paling kecil, dengan nilai 772684.832459, dengan error pada data uji sebesar 5295484.003658
- XGBoost memiliki error di data uji paling kecil 5039267.84, dengan error di data latih sebesar 1106514.176
- Gradient Boosting memiliki error paling besar dari kedua algoritma lain, baik di data latih maupun data uji, dengan masing-masing nilai 4083933.339346 dan 5371753.914372, sehingga model ini kurang efektif dengan dataset ini.
"""

#menampilkan prediksi dari 3 model
prediksi = x_test.iloc[4:5].copy()
pred_dict = {'y_true':y_test[4:5]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Bisa dilihat bahwa prediksi dari XGBoost lebih akurat daripada Random Forest Regressor karena hasil prediksi XGBoost lebih mendekati nilai data aktual.
Sehingga bisa disimpulkan bahwa model yang cocok dengan projek prediksi penjualan harga mobil bekas ini adalah model XGBoost karena memiliki error yang lebih rendah dan nilai prediksi yang mendekati nilai sebenarnya.
"""